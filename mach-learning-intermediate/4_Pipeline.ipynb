{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0157e3ee",
   "metadata": {},
   "source": [
    "# Pipelines\n",
    "Nos permiten realizar de manera organizada el preprocesamiento y el modelado de nuestro algoritmo. Empaqueta todas los procesos en un solo paso. Además, \n",
    "\n",
    "1. **Código más limpio:** aplicar cada paso del prepocesamiento tanto a la data de entreamiento como de validación puede volverse engorroso, de esta manera, se evita ese problema.\n",
    "2. **Menos errores:** hay menos oportunidades donde aplicar mal una instrucción u omitir un paso del procesamiento.\n",
    "3. **Fácil de productizar:** la transición de un modelo desde prototipo a algo escalable y utilizable puede ser muy complicado (por diferentes razones que no se ahonda aún), el uso de pipelines es de gran ayuda en esto.\n",
    "4. **Más opciones de validación:** como el uso de cross-validation.\n",
    "\n",
    "**NOTA:** para mi, cosas de las más importantes, habiendo obtenido algunas conclusiones en el final de la anterior clase son las siguientes:\n",
    "- La posibilidad de realizar de manera sencilla \"imputer\" tanto en variables numéricas como categóricas\n",
    "- Preprocesamiento y Fit del modelo se realizan en un sólo paso\n",
    "- Preprocesamiento de los datos de validación se realizan internamente, dentro de la misma función de predicción (anteriormente, debíamos hacerlo explícitamente antes de ejecutar las predicciones)\n",
    "\n",
    "Veamos directamente su aplicación:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa977c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando...\n",
      "Listo\n"
     ]
    }
   ],
   "source": [
    "# Carga inicial de Data \n",
    "print('Iniciando...')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv('assets/input/train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('assets/input/test.csv', index_col='Id')\n",
    "\n",
    "train_data.dropna(subset=['SalePrice'], axis=0, inplace=True)\n",
    "y = train_data.SalePrice\n",
    "X_full = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "train_X_full, val_X_full, train_y, val_y = train_test_split(X_full, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Listo')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27333d09",
   "metadata": {},
   "source": [
    "Algo importante, una de las únicas acciones que debo implementar manualmente sobre el set de datos es separar *features* numericas de categóricas y, sobre estas últimas, filtrar aquellas que tengan alta cardinalidad (más de 10 valores posibles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dace3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separo columnas numericas y categoricas (+ filtro cardinalidad < 10)\n",
    "numeric_cols = [col for col in train_X_full.columns if train_X_full[col].dtype in ['int64', 'float64']]\n",
    "categoric_cols = [col for col in train_X_full.columns if\n",
    "                      train_X_full[col].dtype == 'object' and\n",
    "                      train_X_full[col].nunique() < 10\n",
    "                 ]\n",
    "\n",
    "# columnas finales a usar de mi dataset \n",
    "final_cols = numeric_cols + categoric_cols\n",
    "train_X = train_X_full[final_cols].copy()\n",
    "val_X = val_X_full[final_cols].copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee564c26",
   "metadata": {},
   "source": [
    "Ahora sí, comienzo a definir los preprocesamientos y el pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bd7ea768",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# Tranformers numerico y categorico (conforman el Preprocesador)\n",
    "# 'median', mejor resultado dio en practicas anteriores\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "\n",
    "# Este transformer a su vez, usa Pipeline xq implica 2 pasos\n",
    "# - imputacion ('most_frequent' por ser categorica)\n",
    "# - codificacion (ordinal, mejor resultado anteriomente)\n",
    "categoric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse=False))\n",
    "])\n",
    "\n",
    "\n",
    "# Combinando ambos\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categoric_transformer, categoric_cols)\n",
    "    ])\n",
    "\n",
    "\n",
    "# Combino Preprocesamiento y modelo en Pipeline\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "pipe_model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7facf69a",
   "metadata": {},
   "source": [
    "Preprocesamiento definido, listo, puedo crear el modelo y realizar las predicciones mediante mi pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "210f7419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (Pipelined): 17553\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# preprocesamiento y fit del modelo en 1 paso\n",
    "pipe_model.fit(train_X, train_y)\n",
    "\n",
    "# prediccion con preprocesamiento de val_data internamente\n",
    "preds = pipe_model.predict(val_X)\n",
    "\n",
    "pipe_mae = mean_absolute_error(val_y, preds)\n",
    "print('MAE (Pipelined): {:.0f}'.format(pipe_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9cb8a0",
   "metadata": {},
   "source": [
    "## Primeras Conclusiones\n",
    "1. En primer lugar, se observa que el código es más estructurado, limpio y legible que sin el uso de Pipeline. Además, evita ciertos pasos que vuelven todo más engorroso y con posibilidad de cometer errores en el proceso.\n",
    "2. En cuanto a la performance obtenida, fue prácticamente igual a la que se obtuvo en el caso de la clase 3 utilizando OneHotEncoder (MAE: 17525) habiendo dropeado los *missing values*, por tanto no hubo mejora en ese sentido, lo cual me generó dudas, ya que en la clase anterior sobre valores nulos, al imputar los mismos (con *median* en este caso) se obtenía una mejora respecto de eliminarlos directamente. \n",
    "\n",
    "Finalmente, pruebo a continuación, qué resultado obtengo si utilizo codificación *OrdinalEncoder* en lugar de *OneHot*, dado que me había entregado mejores resultados anteriormente (MAE: 17098, incluso, en ese caso, no se había realizado imputación de valores missing, que aquí sí se realizará)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6845c88f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando...\n",
      "Listo\n"
     ]
    }
   ],
   "source": [
    "# Carga inicial de Data \n",
    "print('Iniciando...')\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data = pd.read_csv('assets/input/train.csv', index_col='Id')\n",
    "test_data = pd.read_csv('assets/input/test.csv', index_col='Id')\n",
    "\n",
    "train_data.dropna(subset=['SalePrice'], axis=0, inplace=True)\n",
    "y = train_data.SalePrice\n",
    "X_full = train_data.drop(['SalePrice'], axis=1)\n",
    "\n",
    "train_X_full, val_X_full, train_y, val_y = train_test_split(X_full, y, train_size=0.8, test_size=0.2, random_state=0)\n",
    "\n",
    "print('Listo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e441c87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino missings, para que quede igual que en Ej Clase 3 \n",
    "# (drop missing + OrdinalEnc catgs)\n",
    "cols_with_missing = [col for col in X_full.columns if X_full[col].isnull().any()]\n",
    "train_X_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "val_X_full.drop(cols_with_missing, axis=1, inplace=True)\n",
    "\n",
    "numeric_cols = [col for col in train_X_full.columns if train_X_full[col].dtype in ['int64', 'float64']]\n",
    "categoric_cols = [col for col in train_X_full.columns if \n",
    "                      train_X_full[col].dtype == 'object' and\n",
    "                      set(val_X_full[col]).issubset(set(train_X_full[col])) # good_cols, para ord encoder\n",
    "                 ]\n",
    "\n",
    "final_cols = numeric_cols + categoric_cols\n",
    "train_X = train_X_full[final_cols]\n",
    "val_X = val_X_full[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b12617b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (pipe solo OrdinalEncode): 29574\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# numeric_transformer -> No. Dropee las missing \n",
    "categoric_transformer = Pipeline(steps=[\n",
    "    ('ordinal_encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('categoric', categoric_transformer, categoric_cols)\n",
    "])\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "model_pipe.fit(train_X, train_y)\n",
    "preds = model_pipe.predict(val_X)\n",
    "pipe_mae = mean_absolute_error(val_y, preds)\n",
    "print('MAE (pipe solo OrdinalEncode): {:.0f}'.format(pipe_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8198ce01",
   "metadata": {},
   "source": [
    "## Análisis\n",
    "**Dió espantoso (*MAE: 29574)*. Averiguar por qué?** Se supone que hice lo mismo que en el caso de la clase 3: drop de missing values y OrdinalEncode sobre las categóricas.\n",
    "\n",
    "## Prueba final (Imputer + OrdinalEncoder)\n",
    "\n",
    "Para finalizar, **pruebo agregando Imputer a los *missing* ('median' en los numéricos y 'most_frequent' en categóricas)** (la codificación de categóricas mantengo *Ordinal*)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "47361e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [col for col in train_X_full.columns if train_X_full[col].dtype in ['int64', 'float64']]\n",
    "categoric_cols = [col for col in train_X_full.columns if \n",
    "                      train_X_full[col].dtype == 'object' \n",
    "                      # innecesario, si uso handle_unknown en OrdinalEnc\n",
    "                      # Lo use pa sino en test fallara si encuentra un valor desconocido\n",
    "                      # and set(val_X_full[col]).issubset(set(train_X_full[col])) \n",
    "                 ]\n",
    "\n",
    "final_cols = numeric_cols + categoric_cols\n",
    "train_X = train_X_full[final_cols]\n",
    "val_X = val_X_full[final_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "49f03557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE (pipeline, imputer + ordinalEnc): 17165\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "numeric_transformer = SimpleImputer(strategy='median')\n",
    "categoric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('ord_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=30))\n",
    "    #('ord_encoder', OrdinalEncoder())\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numeric_transformer, numeric_cols),\n",
    "    ('cat', categoric_transformer, categoric_cols),\n",
    "])\n",
    "\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=0)\n",
    "model_pipe = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', model)\n",
    "])\n",
    "\n",
    "model_pipe.fit(train_X, train_y)\n",
    "pipe_preds = model_pipe.predict(val_X)\n",
    "pipe_mae = mean_absolute_error(val_y, pipe_preds)\n",
    "\n",
    "print('MAE (pipeline, imputer + ordinalEnc): {:.0f}'.format(pipe_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad2d2e",
   "metadata": {},
   "source": [
    "## Análisis Imputer + OrdinalEncoder\n",
    "En este caso, el resultado mejoró, pero aún me sigue dando peor (por poco, 17098 vs 17217) que en las pruebas sin Pipeline utilizando solo OrdinalEncode y dropeando los *missing*.\n",
    "No obstante, igual realizo lo correspondiente para hacer predicciones con este modelo sobre la data de la competencia (*test.csv*).\n",
    "\n",
    "**NOTA:** despues mejoró un poquito más al quitar la limitación de columnas \"good_cols\", empleando un *handle_unknown* en el OrdinalEncoder. Esto lo hice porque sino, al probar el modelo sobre *test_data* falla al encontrar valores que no hayan sido codificados (es decir que no estuvieran durante el entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ec47bf",
   "metadata": {},
   "source": [
    "## Modelo Final. Predicciones para Competencia\n",
    "Realizo las predicciones sobre la data de la competencia (*test.csv*) aunque el modelo obtenido hasta ahora no fue mejor que el construido en Clase 3 (Drop missing + OrdinalEncoder).\n",
    "\n",
    "**DUDA:** ¿Antes de realizar la predicción, **no debería entrenar al modelo con la data total** (*train + validation*) como se vio en otros casos, para que el modelo sea lo mejor posible?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "710c45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features a utlizar (sin dropeo de missing + good_cols categoricas para OrdinalEncode)\n",
    "test_X = test_data[final_cols]\n",
    "test_preds = model_pipe.predict(test_X)\n",
    "\n",
    "output = pd.DataFrame({'Id': test_X.index, 'SalePrice': test_preds})\n",
    "output.to_csv('assets/output/home_submission_pipeline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fa9085d",
   "metadata": {},
   "source": [
    "**Pruebo entrenar el modelo con la data total**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0f3c20cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_full[final_cols]\n",
    "model_pipe.fit(X, y)\n",
    "final_test_preds = model_pipe.predict(test_X)\n",
    "\n",
    "output = pd.DataFrame({'Id': test_X.index, 'SalePrice': final_test_preds})\n",
    "output.to_csv('assets/output/home_submission_pipeline.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8add879e",
   "metadata": {},
   "source": [
    "## Comentario final\n",
    "Efectivamente, al entrenar el modelo con la data total obtuve una mejora en la performance, obteniendo un *score* de 15887 contra 16340 en el caso anterior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
